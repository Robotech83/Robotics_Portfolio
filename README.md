# ü§ñ Sonny ‚Äî Offline Humanoid Robotics Portfolio

**Status:** Prototype / Active Development  
**Focus:** Robotics Systems ‚Ä¢ Embedded Software ‚Ä¢ Perception ‚Ä¢ Human‚ÄìRobot Interaction

This repository contains my **robotics portfolio and digital twin environment**, built to design, test, and demonstrate an **offline humanoid robot** named **Sonny**.  
The project emphasizes **real-world robotics workflows**: partial hardware, debugging under constraints, simulation-first development, and modular system design.

---

## üß† Project Overview

Sonny is an **offline humanoid robotics platform** designed to explore how perception, voice interaction, motion control, and diagnostics work together in a real robot system.

The portfolio serves as:
- a **digital twin** for hardware-in-progress
- a **control interface** similar to internal robotics dashboards
- a **proof-of-knowledge** artifact for robotics and embedded systems roles

---

## üß© System Architecture

### Core Subsystems

- **Perception**
  - Face detection and tracking
  - Real-time object detection (TensorFlow.js / COCO-SSD)
  - Task-specific perception modules:
    - Clothing detection (folding tasks)
    - Kitchenware detection (dish handling tasks)

- **Voice & Interaction**
  - Wake-word system
  - Offline speech recognition
  - Text-to-speech output
  - Command training and routing

- **Motion & Control**
  - Joint-based motion control
  - Servo angle computation
  - Serial communication to embedded controllers
  - Kinematics visualization (in progress)

- **Digital Twin & Simulation**
  - 3D humanoid model viewer
  - Virtual arm studio
  - Simulation-first workflow when hardware is unavailable

- **System & Diagnostics**
  - CPU / memory monitoring
  - Network and power modules
  - System health and fault-handling UI

---

## üñ•Ô∏è Technologies Used

- **Languages:** Python, TypeScript, JavaScript  
- **Frontend:** React, Vite, Three.js  
- **Robotics & Embedded:** Raspberry Pi, Arduino, Servo Control, Serial Communication  
- **Perception & AI:** OpenCV, TensorFlow.js, COCO-SSD  
- **3D & Simulation:** GLTF (.glb), Blender (source assets kept separate)  
- **Tooling:** Git, Git LFS, Linux

---

## üìä System Status

This project is intentionally transparent about development state.

- ‚úÖ Face detection & object detection working
- ‚úÖ Offline voice pipeline functional
- üü° Motion control limited by current hardware availability
- üü° Kinematics tools actively iterating
- ‚è∏ Some physical components pending repair or redesign

A full system status overview is available inside the portfolio UI.

---

## üéØ Development Philosophy

This project prioritizes **engineering realism over cosmetic completeness**.

Hardware failures, incomplete assemblies, and limited resources are treated as part of the design process. When hardware is unavailable, development continues through simulation, modular testing, and virtual tools.

---

## üöÄ Running the Project Locally

```bash
npm install
npm run dev
